{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cropped Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use cropped decoding. Cropped decoding means the ConvNet is trained on time windows/time crops within the trials. We will explain this visually by comparing trialwise to cropped decoding.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trialwise Decoding | Cropped Decoding\n",
    "- | - \n",
    "![Trialwise Decoding](./trialwise_explanation.png \"Trialwise Decoding\") | ![Cropped Decoding](./cropped_explanation.png \"Cropped Decoding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the left, you see trialwise decoding:\n",
    "\n",
    "1. A complete trial is pushed through the network\n",
    "2. The network produces a prediction\n",
    "3. The prediction is compared to the target (label) for that trial to compute the loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the right, you see cropped decoding:\n",
    "\n",
    "1. Instead of a complete trial, windows within the trial, here called *crops*, are pushed through the network\n",
    "2. For computational efficiency, multiple neighbouring crops are pushed through the network simultaneously (these neighbouring crops are called a *supercrop*)\n",
    "3. Therefore, the network produces multiple predictions (one per crop in the supercrop)\n",
    "4. The individual crop predictions are averaged before computing the loss function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "* The network architecture implicitly defines the crop size (it is the receptive field size, i.e., the number of timesteps the network uses to make a single prediction)\n",
    "* The supercrop size is a user-defined hyperparameter, called `input_time_length` in Braindecode. It mostly affects runtime (larger supercrop sizes should be faster). As a rule of thumb, you can set it to two times the crop size.\n",
    "* Crop size and supercrop size together define how many predictions the network makes per supercrop:  $\\mathrm{\\#supercrop}-\\mathrm{\\#crop}+1=\\mathrm{\\#predictions}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For cropped decoding, the above training setup is mathematically identical to sampling crops in your dataset, pushing them through the network and training directly on the individual crops. At the same time, the above training setup is much faster as it avoids redundant computations by using dilated convolutions, see our paper [Deep learning with convolutional neural networks for EEG decoding and visualization](https://arxiv.org/abs/1703.05051). However, the two setups are only mathematically identical in case (1) your network does not use any padding and (2) your loss function leads to the same gradients when using the averaged output. The first is true for our shallow and deep ConvNet models and the second is true for the log-softmax outputs and negative log likelihood loss that is typically used for classification in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the code for cropped decoding is identical to the [Trialwise Decoding Tutorial](Trialwise_Decoding.html), differences are explained in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging) # see https://stackoverflow.com/a/21475297/1469195\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from mne.io import concatenate_raws\n",
    "\n",
    "# 5,6,7,10,13,14 are codes for executed and imagined hands/feet\n",
    "subject_id = 22\n",
    "event_codes = [5,6,9,10,13,14]\n",
    "#event_codes = [3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "\n",
    "# This will download the files if you don't have them yet,\n",
    "# and then return the paths to the files.\n",
    "physionet_paths = mne.datasets.eegbci.load_data(subject_id, event_codes)\n",
    "\n",
    "# Load each of the files\n",
    "parts = [mne.io.read_raw_edf(path, preload=True,stim_channel='auto', verbose='WARNING')\n",
    "         for path in physionet_paths]\n",
    "\n",
    "# Concatenate them\n",
    "raw = concatenate_raws(parts)\n",
    "\n",
    "# Find the events in this dataset\n",
    "events, _ = mne.events_from_annotations(raw)\n",
    "\n",
    "# Use only EEG channels\n",
    "eeg_channel_inds = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                   exclude='bads')\n",
    "\n",
    "# Extract trials, only using EEG channels\n",
    "epoched = mne.Epochs(raw, events, dict(hands_or_left=2, feet_or_right=3), tmin=1, tmax=4.1, proj=False, picks=eeg_channel_inds,\n",
    "                baseline=None, preload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data to Braindecode format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Convert data from volt to millivolt\n",
    "# Pytorch expects float32 for input and int64 for labels.\n",
    "X = (epoched.get_data() * 1e6).astype(np.float32)\n",
    "y = (epoched.events[:,2] - 2).astype(np.int64) #2,3 -> 0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datautil.signal_target import SignalAndTarget\n",
    "\n",
    "train_set = SignalAndTarget(X[:40], y=y[:40])\n",
    "valid_set = SignalAndTarget(X[40:70], y=y[40:70])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "As in the trialwise decoding tutorial, we will use the Braindecode model class directly to perform the training in a few lines of code. If you instead want to use your own training loop, have a look at the [Cropped Manual Training Loop Tutorial](./Cropped_Manual_Training_Loop.html).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For cropped decoding, we now transform the model into a model that outputs a dense time series of predictions.\n",
    "For this, we manually set the length of the final convolution layer to some length that makes the receptive field of the ConvNet smaller than the number of samples in a trial (see `final_conv_length=12` in the model definition). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from braindecode.models import ShallowFBCSPNet\n",
    "from torch import nn\n",
    "from braindecode.torch_ext.util import set_random_seeds\n",
    "\n",
    "# Set if you want to use GPU\n",
    "# You can also use torch.cuda.is_available() to determine if cuda is available on your machine.\n",
    "cuda = False\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "n_classes = 2\n",
    "in_chans = train_set.X.shape[1]\n",
    "\n",
    "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=n_classes,\n",
    "                        input_time_length=None,\n",
    "                        final_conv_length=12)\n",
    "if cuda:\n",
    "    model.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we supply `cropped=True` to our compile function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.torch_ext.optimizers import AdamW\n",
    "import torch.nn.functional as F\n",
    "#optimizer = AdamW(model.parameters(), lr=1*0.01, weight_decay=0.5*0.001) # these are good values for the deep model\n",
    "optimizer = AdamW(model.parameters(), lr=0.0625 * 0.01, weight_decay=0)\n",
    "model.compile(loss=F.nll_loss, optimizer=optimizer,  iterator_seed=1, cropped=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fitting, we must supply the super crop size. Here, we it to 450 by setting `input_time_length = 450`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-13 17:49:07,369 INFO : Run until first stop...\n",
      "2020-01-13 17:49:08,967 INFO : Epoch 0\n",
      "2020-01-13 17:49:08,968 INFO : train_loss                20.30271\n",
      "2020-01-13 17:49:08,968 INFO : valid_loss                19.24412\n",
      "2020-01-13 17:49:08,968 INFO : train_misclass            0.52500\n",
      "2020-01-13 17:49:08,969 INFO : valid_misclass            0.53333\n",
      "2020-01-13 17:49:08,969 INFO : runtime                   0.00000\n",
      "2020-01-13 17:49:08,970 INFO : \n",
      "2020-01-13 17:49:12,065 INFO : Time only for training updates: 3.09s\n",
      "2020-01-13 17:49:13,294 INFO : Epoch 1\n",
      "2020-01-13 17:49:13,295 INFO : train_loss                7.17172\n",
      "2020-01-13 17:49:13,296 INFO : valid_loss                5.94951\n",
      "2020-01-13 17:49:13,296 INFO : train_misclass            0.52500\n",
      "2020-01-13 17:49:13,297 INFO : valid_misclass            0.53333\n",
      "2020-01-13 17:49:13,297 INFO : runtime                   4.69565\n",
      "2020-01-13 17:49:13,298 INFO : \n",
      "2020-01-13 17:49:16,031 INFO : Time only for training updates: 2.72s\n",
      "2020-01-13 17:49:17,353 INFO : Epoch 2\n",
      "2020-01-13 17:49:17,353 INFO : train_loss                4.32604\n",
      "2020-01-13 17:49:17,354 INFO : valid_loss                3.22325\n",
      "2020-01-13 17:49:17,354 INFO : train_misclass            0.52500\n",
      "2020-01-13 17:49:17,355 INFO : valid_misclass            0.50000\n",
      "2020-01-13 17:49:17,355 INFO : runtime                   3.96533\n",
      "2020-01-13 17:49:17,356 INFO : \n",
      "2020-01-13 17:49:20,123 INFO : Time only for training updates: 2.76s\n",
      "2020-01-13 17:49:21,392 INFO : Epoch 3\n",
      "2020-01-13 17:49:21,392 INFO : train_loss                2.71079\n",
      "2020-01-13 17:49:21,393 INFO : valid_loss                1.87292\n",
      "2020-01-13 17:49:21,393 INFO : train_misclass            0.50000\n",
      "2020-01-13 17:49:21,394 INFO : valid_misclass            0.46667\n",
      "2020-01-13 17:49:21,394 INFO : runtime                   4.09208\n",
      "2020-01-13 17:49:21,395 INFO : \n",
      "2020-01-13 17:49:24,383 INFO : Time only for training updates: 2.98s\n",
      "2020-01-13 17:49:25,634 INFO : Epoch 4\n",
      "2020-01-13 17:49:25,635 INFO : train_loss                1.59652\n",
      "2020-01-13 17:49:25,635 INFO : valid_loss                1.09704\n",
      "2020-01-13 17:49:25,636 INFO : train_misclass            0.45000\n",
      "2020-01-13 17:49:25,636 INFO : valid_misclass            0.40000\n",
      "2020-01-13 17:49:25,637 INFO : runtime                   4.26040\n",
      "2020-01-13 17:49:25,637 INFO : \n",
      "2020-01-13 17:49:28,317 INFO : Time only for training updates: 2.67s\n",
      "2020-01-13 17:49:29,612 INFO : Epoch 5\n",
      "2020-01-13 17:49:29,613 INFO : train_loss                0.99789\n",
      "2020-01-13 17:49:29,613 INFO : valid_loss                0.76181\n",
      "2020-01-13 17:49:29,614 INFO : train_misclass            0.37500\n",
      "2020-01-13 17:49:29,614 INFO : valid_misclass            0.30000\n",
      "2020-01-13 17:49:29,615 INFO : runtime                   3.93377\n",
      "2020-01-13 17:49:29,615 INFO : \n",
      "2020-01-13 17:49:32,311 INFO : Time only for training updates: 2.69s\n",
      "2020-01-13 17:49:33,535 INFO : Epoch 6\n",
      "2020-01-13 17:49:33,536 INFO : train_loss                0.67478\n",
      "2020-01-13 17:49:33,536 INFO : valid_loss                0.61213\n",
      "2020-01-13 17:49:33,537 INFO : train_misclass            0.30000\n",
      "2020-01-13 17:49:33,537 INFO : valid_misclass            0.20000\n",
      "2020-01-13 17:49:33,538 INFO : runtime                   3.99428\n",
      "2020-01-13 17:49:33,538 INFO : \n",
      "2020-01-13 17:49:36,178 INFO : Time only for training updates: 2.63s\n",
      "2020-01-13 17:49:37,394 INFO : Epoch 7\n",
      "2020-01-13 17:49:37,395 INFO : train_loss                0.48404\n",
      "2020-01-13 17:49:37,395 INFO : valid_loss                0.54865\n",
      "2020-01-13 17:49:37,396 INFO : train_misclass            0.20000\n",
      "2020-01-13 17:49:37,397 INFO : valid_misclass            0.13333\n",
      "2020-01-13 17:49:37,398 INFO : runtime                   3.86737\n",
      "2020-01-13 17:49:37,398 INFO : \n",
      "2020-01-13 17:49:40,112 INFO : Time only for training updates: 2.70s\n",
      "2020-01-13 17:49:41,376 INFO : Epoch 8\n",
      "2020-01-13 17:49:41,377 INFO : train_loss                0.38079\n",
      "2020-01-13 17:49:41,377 INFO : valid_loss                0.53748\n",
      "2020-01-13 17:49:41,377 INFO : train_misclass            0.15000\n",
      "2020-01-13 17:49:41,378 INFO : valid_misclass            0.16667\n",
      "2020-01-13 17:49:41,378 INFO : runtime                   3.93334\n",
      "2020-01-13 17:49:41,379 INFO : \n",
      "2020-01-13 17:49:44,305 INFO : Time only for training updates: 2.92s\n",
      "2020-01-13 17:49:45,700 INFO : Epoch 9\n",
      "2020-01-13 17:49:45,700 INFO : train_loss                0.32552\n",
      "2020-01-13 17:49:45,701 INFO : valid_loss                0.55466\n",
      "2020-01-13 17:49:45,701 INFO : train_misclass            0.12500\n",
      "2020-01-13 17:49:45,702 INFO : valid_misclass            0.20000\n",
      "2020-01-13 17:49:45,702 INFO : runtime                   4.19353\n",
      "2020-01-13 17:49:45,703 INFO : \n",
      "2020-01-13 17:49:48,605 INFO : Time only for training updates: 2.89s\n",
      "2020-01-13 17:49:49,962 INFO : Epoch 10\n",
      "2020-01-13 17:49:49,963 INFO : train_loss                0.30780\n",
      "2020-01-13 17:49:49,963 INFO : valid_loss                0.59232\n",
      "2020-01-13 17:49:49,963 INFO : train_misclass            0.15000\n",
      "2020-01-13 17:49:49,964 INFO : valid_misclass            0.26667\n",
      "2020-01-13 17:49:49,965 INFO : runtime                   4.29927\n",
      "2020-01-13 17:49:49,965 INFO : \n",
      "2020-01-13 17:49:53,341 INFO : Time only for training updates: 3.37s\n",
      "2020-01-13 17:49:54,800 INFO : Epoch 11\n",
      "2020-01-13 17:49:54,801 INFO : train_loss                0.30212\n",
      "2020-01-13 17:49:54,801 INFO : valid_loss                0.63135\n",
      "2020-01-13 17:49:54,802 INFO : train_misclass            0.15000\n",
      "2020-01-13 17:49:54,803 INFO : valid_misclass            0.30000\n",
      "2020-01-13 17:49:54,803 INFO : runtime                   4.73628\n",
      "2020-01-13 17:49:54,804 INFO : \n",
      "2020-01-13 17:49:57,722 INFO : Time only for training updates: 2.90s\n",
      "2020-01-13 17:49:59,007 INFO : Epoch 12\n",
      "2020-01-13 17:49:59,008 INFO : train_loss                0.28295\n",
      "2020-01-13 17:49:59,009 INFO : valid_loss                0.64258\n",
      "2020-01-13 17:49:59,009 INFO : train_misclass            0.12500\n",
      "2020-01-13 17:49:59,010 INFO : valid_misclass            0.30000\n",
      "2020-01-13 17:49:59,010 INFO : runtime                   4.38111\n",
      "2020-01-13 17:49:59,011 INFO : \n",
      "2020-01-13 17:50:02,020 INFO : Time only for training updates: 3.00s\n",
      "2020-01-13 17:50:03,283 INFO : Epoch 13\n",
      "2020-01-13 17:50:03,284 INFO : train_loss                0.25185\n",
      "2020-01-13 17:50:03,285 INFO : valid_loss                0.63019\n",
      "2020-01-13 17:50:03,285 INFO : train_misclass            0.10000\n",
      "2020-01-13 17:50:03,286 INFO : valid_misclass            0.30000\n",
      "2020-01-13 17:50:03,286 INFO : runtime                   4.29752\n",
      "2020-01-13 17:50:03,286 INFO : \n",
      "2020-01-13 17:50:06,117 INFO : Time only for training updates: 2.82s\n",
      "2020-01-13 17:50:07,389 INFO : Epoch 14\n",
      "2020-01-13 17:50:07,389 INFO : train_loss                0.21835\n",
      "2020-01-13 17:50:07,390 INFO : valid_loss                0.60792\n",
      "2020-01-13 17:50:07,390 INFO : train_misclass            0.07500\n",
      "2020-01-13 17:50:07,391 INFO : valid_misclass            0.30000\n",
      "2020-01-13 17:50:07,391 INFO : runtime                   4.09793\n",
      "2020-01-13 17:50:07,392 INFO : \n",
      "2020-01-13 17:50:10,187 INFO : Time only for training updates: 2.79s\n",
      "2020-01-13 17:50:11,483 INFO : Epoch 15\n",
      "2020-01-13 17:50:11,484 INFO : train_loss                0.18942\n",
      "2020-01-13 17:50:11,484 INFO : valid_loss                0.58374\n",
      "2020-01-13 17:50:11,485 INFO : train_misclass            0.07500\n",
      "2020-01-13 17:50:11,486 INFO : valid_misclass            0.30000\n",
      "2020-01-13 17:50:11,486 INFO : runtime                   4.06908\n",
      "2020-01-13 17:50:11,487 INFO : \n",
      "2020-01-13 17:50:14,424 INFO : Time only for training updates: 2.93s\n",
      "2020-01-13 17:50:15,729 INFO : Epoch 16\n",
      "2020-01-13 17:50:15,730 INFO : train_loss                0.16523\n",
      "2020-01-13 17:50:15,730 INFO : valid_loss                0.56021\n",
      "2020-01-13 17:50:15,731 INFO : train_misclass            0.05000\n",
      "2020-01-13 17:50:15,732 INFO : valid_misclass            0.26667\n",
      "2020-01-13 17:50:15,732 INFO : runtime                   4.23700\n",
      "2020-01-13 17:50:15,733 INFO : \n",
      "2020-01-13 17:50:18,666 INFO : Time only for training updates: 2.92s\n",
      "2020-01-13 17:50:19,908 INFO : Epoch 17\n",
      "2020-01-13 17:50:19,909 INFO : train_loss                0.14511\n",
      "2020-01-13 17:50:19,910 INFO : valid_loss                0.53870\n",
      "2020-01-13 17:50:19,910 INFO : train_misclass            0.05000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-13 17:50:19,911 INFO : valid_misclass            0.20000\n",
      "2020-01-13 17:50:19,911 INFO : runtime                   4.24223\n",
      "2020-01-13 17:50:19,912 INFO : \n",
      "2020-01-13 17:50:22,548 INFO : Time only for training updates: 2.63s\n",
      "2020-01-13 17:50:23,826 INFO : Epoch 18\n",
      "2020-01-13 17:50:23,826 INFO : train_loss                0.12788\n",
      "2020-01-13 17:50:23,827 INFO : valid_loss                0.51953\n",
      "2020-01-13 17:50:23,827 INFO : train_misclass            0.00000\n",
      "2020-01-13 17:50:23,828 INFO : valid_misclass            0.16667\n",
      "2020-01-13 17:50:23,828 INFO : runtime                   3.88180\n",
      "2020-01-13 17:50:23,829 INFO : \n",
      "2020-01-13 17:50:26,551 INFO : Time only for training updates: 2.71s\n",
      "2020-01-13 17:50:27,809 INFO : Epoch 19\n",
      "2020-01-13 17:50:27,810 INFO : train_loss                0.11284\n",
      "2020-01-13 17:50:27,811 INFO : valid_loss                0.50268\n",
      "2020-01-13 17:50:27,811 INFO : train_misclass            0.00000\n",
      "2020-01-13 17:50:27,812 INFO : valid_misclass            0.13333\n",
      "2020-01-13 17:50:27,812 INFO : runtime                   4.00348\n",
      "2020-01-13 17:50:27,813 INFO : \n",
      "2020-01-13 17:50:30,455 INFO : Time only for training updates: 2.63s\n",
      "2020-01-13 17:50:31,697 INFO : Epoch 20\n",
      "2020-01-13 17:50:31,698 INFO : train_loss                0.10012\n",
      "2020-01-13 17:50:31,698 INFO : valid_loss                0.48864\n",
      "2020-01-13 17:50:31,699 INFO : train_misclass            0.00000\n",
      "2020-01-13 17:50:31,699 INFO : valid_misclass            0.13333\n",
      "2020-01-13 17:50:31,700 INFO : runtime                   3.90380\n",
      "2020-01-13 17:50:31,700 INFO : \n",
      "2020-01-13 17:50:34,325 INFO : Time only for training updates: 2.62s\n",
      "2020-01-13 17:50:35,618 INFO : Epoch 21\n",
      "2020-01-13 17:50:35,619 INFO : train_loss                0.08962\n",
      "2020-01-13 17:50:35,619 INFO : valid_loss                0.47757\n",
      "2020-01-13 17:50:35,620 INFO : train_misclass            0.00000\n",
      "2020-01-13 17:50:35,620 INFO : valid_misclass            0.13333\n",
      "2020-01-13 17:50:35,621 INFO : runtime                   3.87000\n",
      "2020-01-13 17:50:35,621 INFO : \n",
      "2020-01-13 17:50:38,446 INFO : Time only for training updates: 2.82s\n",
      "2020-01-13 17:50:39,731 INFO : Epoch 22\n",
      "2020-01-13 17:50:39,731 INFO : train_loss                0.08130\n",
      "2020-01-13 17:50:39,732 INFO : valid_loss                0.46904\n",
      "2020-01-13 17:50:39,732 INFO : train_misclass            0.00000\n",
      "2020-01-13 17:50:39,733 INFO : valid_misclass            0.13333\n",
      "2020-01-13 17:50:39,734 INFO : runtime                   4.12076\n",
      "2020-01-13 17:50:39,734 INFO : \n",
      "2020-01-13 17:50:42,475 INFO : Time only for training updates: 2.73s\n",
      "2020-01-13 17:50:43,761 INFO : Epoch 23\n",
      "2020-01-13 17:50:43,762 INFO : train_loss                0.07503\n",
      "2020-01-13 17:50:43,762 INFO : valid_loss                0.46279\n",
      "2020-01-13 17:50:43,762 INFO : train_misclass            0.00000\n",
      "2020-01-13 17:50:43,763 INFO : valid_misclass            0.13333\n",
      "2020-01-13 17:50:43,763 INFO : runtime                   4.02915\n",
      "2020-01-13 17:50:43,764 INFO : \n",
      "2020-01-13 17:50:46,584 INFO : Time only for training updates: 2.81s\n",
      "2020-01-13 17:50:47,857 INFO : Epoch 24\n",
      "2020-01-13 17:50:47,858 INFO : train_loss                0.07020\n",
      "2020-01-13 17:50:47,858 INFO : valid_loss                0.45800\n",
      "2020-01-13 17:50:47,858 INFO : train_misclass            0.00000\n",
      "2020-01-13 17:50:47,859 INFO : valid_misclass            0.16667\n",
      "2020-01-13 17:50:47,860 INFO : runtime                   4.10915\n",
      "2020-01-13 17:50:47,860 INFO : \n",
      "2020-01-13 17:50:50,560 INFO : Time only for training updates: 2.69s\n",
      "2020-01-13 17:50:51,822 INFO : Epoch 25\n",
      "2020-01-13 17:50:51,823 INFO : train_loss                0.06665\n",
      "2020-01-13 17:50:51,824 INFO : valid_loss                0.45426\n",
      "2020-01-13 17:50:51,824 INFO : train_misclass            0.00000\n",
      "2020-01-13 17:50:51,825 INFO : valid_misclass            0.13333\n",
      "2020-01-13 17:50:51,825 INFO : runtime                   3.97649\n",
      "2020-01-13 17:50:51,826 INFO : \n",
      "2020-01-13 17:50:54,526 INFO : Time only for training updates: 2.69s\n",
      "2020-01-13 17:50:55,788 INFO : Epoch 26\n",
      "2020-01-13 17:50:55,788 INFO : train_loss                0.06397\n",
      "2020-01-13 17:50:55,789 INFO : valid_loss                0.45125\n",
      "2020-01-13 17:50:55,789 INFO : train_misclass            0.00000\n",
      "2020-01-13 17:50:55,790 INFO : valid_misclass            0.16667\n",
      "2020-01-13 17:50:55,790 INFO : runtime                   3.96613\n",
      "2020-01-13 17:50:55,791 INFO : \n",
      "2020-01-13 17:50:58,591 INFO : Time only for training updates: 2.79s\n",
      "2020-01-13 17:50:59,806 INFO : Epoch 27\n",
      "2020-01-13 17:50:59,807 INFO : train_loss                0.06199\n",
      "2020-01-13 17:50:59,807 INFO : valid_loss                0.44875\n",
      "2020-01-13 17:50:59,807 INFO : train_misclass            0.00000\n",
      "2020-01-13 17:50:59,808 INFO : valid_misclass            0.16667\n",
      "2020-01-13 17:50:59,808 INFO : runtime                   4.06404\n",
      "2020-01-13 17:50:59,809 INFO : \n",
      "2020-01-13 17:51:02,484 INFO : Time only for training updates: 2.67s\n",
      "2020-01-13 17:51:03,744 INFO : Epoch 28\n",
      "2020-01-13 17:51:03,744 INFO : train_loss                0.06055\n",
      "2020-01-13 17:51:03,745 INFO : valid_loss                0.44675\n",
      "2020-01-13 17:51:03,745 INFO : train_misclass            0.00000\n",
      "2020-01-13 17:51:03,746 INFO : valid_misclass            0.16667\n",
      "2020-01-13 17:51:03,746 INFO : runtime                   3.89375\n",
      "2020-01-13 17:51:03,747 INFO : \n",
      "2020-01-13 17:51:06,495 INFO : Time only for training updates: 2.74s\n",
      "2020-01-13 17:51:07,683 INFO : Epoch 29\n",
      "2020-01-13 17:51:07,683 INFO : train_loss                0.05950\n",
      "2020-01-13 17:51:07,684 INFO : valid_loss                0.44509\n",
      "2020-01-13 17:51:07,684 INFO : train_misclass            0.00000\n",
      "2020-01-13 17:51:07,685 INFO : valid_misclass            0.16667\n",
      "2020-01-13 17:51:07,685 INFO : runtime                   4.01043\n",
      "2020-01-13 17:51:07,685 INFO : \n",
      "2020-01-13 17:51:10,431 INFO : Time only for training updates: 2.74s\n",
      "2020-01-13 17:51:11,678 INFO : Epoch 30\n",
      "2020-01-13 17:51:11,679 INFO : train_loss                0.05872\n",
      "2020-01-13 17:51:11,680 INFO : valid_loss                0.44372\n",
      "2020-01-13 17:51:11,680 INFO : train_misclass            0.00000\n",
      "2020-01-13 17:51:11,681 INFO : valid_misclass            0.16667\n",
      "2020-01-13 17:51:11,682 INFO : runtime                   3.93609\n",
      "2020-01-13 17:51:11,682 INFO : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<braindecode.experiments.experiment.Experiment at 0x7fcc204bbed0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_time_length = 450\n",
    "model.fit(train_set.X, train_set.y, n_epochs=30, batch_size=64, scheduler='cosine',\n",
    "          input_time_length=input_time_length,\n",
    "         validation_data=(valid_set.X, valid_set.y),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>train_misclass</th>\n",
       "      <th>valid_misclass</th>\n",
       "      <th>runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.302706</td>\n",
       "      <td>19.244120</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.171721</td>\n",
       "      <td>5.949515</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>4.695646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.326042</td>\n",
       "      <td>3.223247</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.965332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.710786</td>\n",
       "      <td>1.872921</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>4.092076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.596519</td>\n",
       "      <td>1.097036</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>4.260404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.997887</td>\n",
       "      <td>0.761809</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>3.933767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.674779</td>\n",
       "      <td>0.612125</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>3.994275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.484044</td>\n",
       "      <td>0.548652</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>3.867371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.380794</td>\n",
       "      <td>0.537480</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>3.933336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.325519</td>\n",
       "      <td>0.554661</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>4.193529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.307801</td>\n",
       "      <td>0.592319</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>4.299274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.302122</td>\n",
       "      <td>0.631353</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>4.736279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.282946</td>\n",
       "      <td>0.642585</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>4.381114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.251845</td>\n",
       "      <td>0.630194</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>4.297523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.218353</td>\n",
       "      <td>0.607916</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>4.097934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.189424</td>\n",
       "      <td>0.583743</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>4.069085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.165230</td>\n",
       "      <td>0.560213</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>4.236997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.145114</td>\n",
       "      <td>0.538696</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>4.242229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.127879</td>\n",
       "      <td>0.519532</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>3.881805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.112837</td>\n",
       "      <td>0.502678</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>4.003478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.100116</td>\n",
       "      <td>0.488642</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>3.903796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.089618</td>\n",
       "      <td>0.477569</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>3.870003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.081304</td>\n",
       "      <td>0.469043</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>4.120761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.075033</td>\n",
       "      <td>0.462789</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>4.029148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.070205</td>\n",
       "      <td>0.457998</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>4.109147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.066650</td>\n",
       "      <td>0.454261</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>3.976492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.063966</td>\n",
       "      <td>0.451254</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>3.966129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.061991</td>\n",
       "      <td>0.448753</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>4.064043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.060554</td>\n",
       "      <td>0.446752</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>3.893754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.059503</td>\n",
       "      <td>0.445089</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>4.010434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.058719</td>\n",
       "      <td>0.443720</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>3.936092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_loss  valid_loss  train_misclass  valid_misclass   runtime\n",
       "0    20.302706   19.244120           0.525        0.533333  0.000000\n",
       "1     7.171721    5.949515           0.525        0.533333  4.695646\n",
       "2     4.326042    3.223247           0.525        0.500000  3.965332\n",
       "3     2.710786    1.872921           0.500        0.466667  4.092076\n",
       "4     1.596519    1.097036           0.450        0.400000  4.260404\n",
       "5     0.997887    0.761809           0.375        0.300000  3.933767\n",
       "6     0.674779    0.612125           0.300        0.200000  3.994275\n",
       "7     0.484044    0.548652           0.200        0.133333  3.867371\n",
       "8     0.380794    0.537480           0.150        0.166667  3.933336\n",
       "9     0.325519    0.554661           0.125        0.200000  4.193529\n",
       "10    0.307801    0.592319           0.150        0.266667  4.299274\n",
       "11    0.302122    0.631353           0.150        0.300000  4.736279\n",
       "12    0.282946    0.642585           0.125        0.300000  4.381114\n",
       "13    0.251845    0.630194           0.100        0.300000  4.297523\n",
       "14    0.218353    0.607916           0.075        0.300000  4.097934\n",
       "15    0.189424    0.583743           0.075        0.300000  4.069085\n",
       "16    0.165230    0.560213           0.050        0.266667  4.236997\n",
       "17    0.145114    0.538696           0.050        0.200000  4.242229\n",
       "18    0.127879    0.519532           0.000        0.166667  3.881805\n",
       "19    0.112837    0.502678           0.000        0.133333  4.003478\n",
       "20    0.100116    0.488642           0.000        0.133333  3.903796\n",
       "21    0.089618    0.477569           0.000        0.133333  3.870003\n",
       "22    0.081304    0.469043           0.000        0.133333  4.120761\n",
       "23    0.075033    0.462789           0.000        0.133333  4.029148\n",
       "24    0.070205    0.457998           0.000        0.166667  4.109147\n",
       "25    0.066650    0.454261           0.000        0.133333  3.976492\n",
       "26    0.063966    0.451254           0.000        0.166667  3.966129\n",
       "27    0.061991    0.448753           0.000        0.166667  4.064043\n",
       "28    0.060554    0.446752           0.000        0.166667  3.893754\n",
       "29    0.059503    0.445089           0.000        0.166667  4.010434\n",
       "30    0.058719    0.443720           0.000        0.166667  3.936092"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.epochs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually, we arrive at 90% accuracy, so 27 from 30 trials are correctly predicted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.46323806047439575,\n",
       " 'misclass': 0.15000000000000002,\n",
       " 'runtime': 0.0005068778991699219}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = SignalAndTarget(X[70:], y=y[70:])\n",
    "\n",
    "model.evaluate(test_set.X, test_set.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now predict entire trials as before or individual crops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_set.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.1952435 , -0.54510456],\n",
       "       [-0.05865435, -3.3187828 ],\n",
       "       [-1.465686  , -0.7026442 ],\n",
       "       [-0.09450155, -3.0328774 ],\n",
       "       [-0.0284515 , -4.385389  ],\n",
       "       [-0.00693051, -5.2352915 ],\n",
       "       [-3.5844257 , -0.20425275],\n",
       "       [-0.39406726, -1.4822389 ],\n",
       "       [-0.01973766, -4.254665  ],\n",
       "       [-0.20424142, -4.0091424 ],\n",
       "       [-0.90883666, -0.6412064 ],\n",
       "       [-2.8004482 , -0.31948426],\n",
       "       [-0.694196  , -1.0596985 ],\n",
       "       [-1.1555578 , -0.49371663],\n",
       "       [-0.1265099 , -2.686141  ],\n",
       "       [-1.2716458 , -0.77929556],\n",
       "       [-2.8155317 , -0.33894047],\n",
       "       [-1.2942142 , -0.5856274 ],\n",
       "       [-0.3505226 , -2.0671346 ],\n",
       "       [-0.63738656, -1.3469466 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_outs(test_set.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For individual crops, provide `individual_crops=True`. This for example can be useful to plot accuracies over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('seaborn')\n",
    "labels_per_trial_per_crop = model.predict(test_set.X, individual_crops=True)\n",
    "accs_per_crop = [l == y for l,y in zip(labels_per_trial_per_crop, test_set.y)]\n",
    "accs_per_crop = np.mean(accs_per_crop, axis=0)\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.plot(accs_per_crop * 100)\n",
    "plt.title(\"Accuracies per timestep\", fontsize=16)\n",
    "plt.xlabel('Timestep in trial', fontsize=14)\n",
    "plt.ylabel('Accuracy [%]', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw outputs could be used to visualize a prediction probability across a trial. Here we look at the first trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_outs = model.predict_outs(test_set.X, individual_crops=True)\n",
    "i_trial = 0\n",
    "# log-softmax outputs need to be exponentiated to get probabilities\n",
    "cropped_probs = np.exp(cropped_outs[i_trial])\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.plot(cropped_probs.T)\n",
    "plt.title(\"Network probabilities for trial {:d} of class {:d}\".format(\n",
    "    i_trial, test_set.y[i_trial]), fontsize=16)\n",
    "plt.legend((\"Class 0\", \"Class 1\"), fontsize=12)\n",
    "plt.xlabel(\"Timestep within trial\", fontsize=14)\n",
    "plt.ylabel(\"Probabilities\", fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset references\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This dataset was created and contributed to PhysioNet by the developers of the [BCI2000](http://www.schalklab.org/research/bci2000) instrumentation system, which they used in making these recordings. The system is described in:\n",
    " \n",
    "     Schalk, G., McFarland, D.J., Hinterberger, T., Birbaumer, N., Wolpaw, J.R. (2004) BCI2000: A General-Purpose Brain-Computer Interface (BCI) System. IEEE TBME 51(6):1034-1043.\n",
    "\n",
    "[PhysioBank](https://physionet.org/physiobank/) is a large and growing archive of well-characterized digital recordings of physiologic signals and related data for use by the biomedical research community and further described in:\n",
    "\n",
    "    Goldberger AL, Amaral LAN, Glass L, Hausdorff JM, Ivanov PCh, Mark RG, Mietus JE, Moody GB, Peng C-K, Stanley HE. (2000) PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research Resource for Complex Physiologic Signals. Circulation 101(23):e215-e220."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
